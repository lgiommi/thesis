As you have already seen, from last week we have solved (thanks to Jim) two uproot issues, one about the loading of the ROOT file (where before it stops at less events than the total) and the other about the possibility to use the vector<bool> type also. I am very happy for these two improvements because now I can go forward.

I discussed with Daniele earlier this week (as we usually do when there are any issues or evident progresses). We agreed that now we can use uproot to migrate from an input root file to a ML-manageable CSV file, we consider the "Data preparation" phase done. We discussed about the need to open (and quickly finish) a "Data validation" phase, which - as a minimum - should aim at verifying that all ROOT-imported data are organized in a correct way in the creayed CSV. I set up this phase on a Jupiter notebook, and I am already done with this too. I am able to reproduce the same ROOT plots inside the notebook that I can browse (TBrowse) on the original ROOT file I am considering now. This gives us the confidence that we now have in hands in CSV form a correct dataset and we can build on this further getting into ML model creation. For the records, this was done on the ROOT file from the hadronic top analysis, but - aiming to be as general as possible - I coded it in a way that would work on any other ROOT file (i.e. loops over all existing branches etc) - despite I did not try this on other ROOT files explicitly in the interest of time. I would consider this a simple "root to csv validation notebook", so to say. You can find my notebook here

https://github.com/lgiommi/thesis/blob/master/csv_root_validation.ipynb

https://github.com/lgiommi/thesis/blob/master/Loading_CSV.ipynb

where the first one needs to check if the plots created using the csv file and the ROOT file are the same; the second one needs to load the data from the csv file into a dictionary (for next ML tasks).


Next: now, I am digging into ML. Idea is to build a model for each use-case I manage to have success with, and then capitalize from the fact I wrote the preparation step with reader.py/uproot to explore and try to insert this model in the TFaaS approach. Of course, I need at elast one decent working ML model! Comments welcome if I misunderstood something.

Another information for you (again from discussion with Daniele). For family and taxes reasons, I was asking Daniele if we could make it to graduate in the next session, i.e. discuss on March 23rd, which means deliver the thesis by March 2nd. Daniele stated that it would be better to aim for June 2018, but he agreed to make an effort with me to try for March. Additionally, he seems to be trying very seriously :) as he asked for a talk in Taipei he has to give to be moved in the agenda earlier in the week to have time to travel back to Italy for my graduation on March 23rd. Just to give you the timeline we have in mind..

You can find in my thesis github repo https://github.com/lgiommi/thesis the csv and root files I used for the notebook.